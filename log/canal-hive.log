2017-03-14 21:26:21.944 WARN  [main] [10.139.53.62] org.apache.hadoop.util.NativeCodeLoader.<clinit>(NativeCodeLoader.java:62) :- Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-03-14 21:26:22.039 ERROR [main] [10.139.53.62] org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:378) :- Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable D:\MyLib\hadoop-2.6.1\hadoop-2.6.1\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:360)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:375)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:368)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:130)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:94)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:74)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:303)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:804)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at chapter02.MyTestHive$.main(MyTestHive.scala:12)
	at chapter02.MyTestHive.main(MyTestHive.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:147)
2017-03-14 21:26:51.510 WARN  [main] [10.139.53.62] org.apache.hadoop.util.NativeCodeLoader.<clinit>(NativeCodeLoader.java:62) :- Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-03-14 21:26:51.610 ERROR [main] [10.139.53.62] org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:378) :- Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable D:\MyLib\hadoop-2.6.1\hadoop-2.6.1\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:360)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:375)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:368)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:130)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:94)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:74)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:303)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:804)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at chapter02.MyTestHive$.main(MyTestHive.scala:12)
	at chapter02.MyTestHive.main(MyTestHive.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:147)
2017-03-14 21:27:39.563 WARN  [main] [10.139.53.62] org.apache.hadoop.util.NativeCodeLoader.<clinit>(NativeCodeLoader.java:62) :- Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-03-14 21:27:39.659 ERROR [main] [10.139.53.62] org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:378) :- Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable D:\MyLib\hadoop-2.6.1\hadoop-2.6.1\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:360)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:375)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:368)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:130)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:94)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:74)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:303)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:804)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at chapter02.MyTestHive$.main(MyTestHive.scala:13)
	at chapter02.MyTestHive.main(MyTestHive.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:147)
2017-03-14 21:27:46.382 WARN  [main] [10.139.53.62] org.apache.hadoop.hive.metastore.ObjectStore.checkSchema(ObjectStore.java:6666) :- Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
2017-03-14 21:27:46.498 WARN  [main] [10.139.53.62] org.apache.hadoop.hive.metastore.ObjectStore.getDatabase(ObjectStore.java:568) :- Failed to get database default, returning NoSuchObjectException
2017-03-14 21:27:47.853 WARN  [main] [10.139.53.62] tachyon.util.network.NetworkAddressUtils.getLocalIpAddress(NetworkAddressUtils.java:389) :- Your hostname, fengbin-pc resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:8ca%20, but we couldn't find any external IP address!
2017-03-14 21:27:50.440 ERROR [Thread-3] [10.139.53.62] org.apache.spark.Logging$class.logError(Logging.scala:95) :- Exception while deleting Spark temp dir: C:\Users\ASUS\AppData\Local\Temp\spark-cc194ec8-a608-4e88-9af0-ca96893dd815
java.io.IOException: Failed to delete: C:\Users\ASUS\AppData\Local\Temp\spark-cc194ec8-a608-4e88-9af0-ca96893dd815
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:929)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:267)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:239)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:239)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:239)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1801)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:239)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:239)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:239)
	at scala.util.Try$.apply(Try.scala:161)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:239)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:218)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
2017-03-14 21:28:31.700 WARN  [main] [10.139.53.62] org.apache.hadoop.util.NativeCodeLoader.<clinit>(NativeCodeLoader.java:62) :- Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-03-14 21:28:31.819 ERROR [main] [10.139.53.62] org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:378) :- Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable D:\MyLib\hadoop-2.6.1\hadoop-2.6.1\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:360)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:375)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:368)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:130)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:94)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:74)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:303)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:804)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2198)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:322)
	at chapter02.MyTestHive$.main(MyTestHive.scala:13)
	at chapter02.MyTestHive.main(MyTestHive.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:147)
2017-03-14 21:28:39.754 WARN  [main] [10.139.53.62] org.apache.hadoop.hive.metastore.ObjectStore.checkSchema(ObjectStore.java:6666) :- Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
2017-03-14 21:28:39.860 WARN  [main] [10.139.53.62] org.apache.hadoop.hive.metastore.ObjectStore.getDatabase(ObjectStore.java:568) :- Failed to get database default, returning NoSuchObjectException
2017-03-14 21:28:41.208 WARN  [main] [10.139.53.62] tachyon.util.network.NetworkAddressUtils.getLocalIpAddress(NetworkAddressUtils.java:389) :- Your hostname, fengbin-pc resolves to a loopback/non-reachable address: fe80:0:0:0:0:5efe:c0a8:8ca%20, but we couldn't find any external IP address!
2017-03-14 21:28:42.802 ERROR [Thread-3] [10.139.53.62] org.apache.spark.Logging$class.logError(Logging.scala:95) :- Exception while deleting Spark temp dir: C:\Users\ASUS\AppData\Local\Temp\spark-662c9f5a-e80c-4eec-9a22-20b907b3fe5f
java.io.IOException: Failed to delete: C:\Users\ASUS\AppData\Local\Temp\spark-662c9f5a-e80c-4eec-9a22-20b907b3fe5f
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:929)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:267)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:239)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:239)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:239)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1801)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:239)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:239)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:239)
	at scala.util.Try$.apply(Try.scala:161)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:239)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:218)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
